# Human and Machine Learning

## Overview

This course presents an outline of human and machine learning. As the title suggests, this involves a process of comparison and contrast: what is common to both human and machine learning, and what distinguishes them. 


---


This process is something that, for this course, I want to approach in a philosophical way. What I mean by this is that, alongside texts from areas of child psychology, linguistics and computer science, I want us to investigate the idea of "learning" through a fundamentally *philosophical* type of inquiry. This I think leads us to think about less about learning as a set of features that pertain to humans, machines or both, and more about learning as itself a process that ranges across a set of common distinctions: between human and machine, but also between individual and society, between child and adult, and so on. It will also help us, I hope, to think about learning as something cooperative, involving both social and technical, or what are sometimes thought as sociotechnical systems. I've coined the term "symbiotic pedagogy" to describe this kind of cooperation. Finally, we might conclude by developing some normative claims: about what constitutes legitimate as opposed to illegitimate forms of human and machine learning. 

---

The presentation of the course will be unusual. I plan to develop and deliver the lecture material offline, and then use the weekly hour allocated to us to discuss both that material and associated readings. This will in some ways add more labor and time to the course, but also allow us to plumb more deeply into a complex topic that ranges across disciplinary fields.

---

For this year (at least), I plan to develop this philosophical lens around the work of a specific philosopher, Georg Friedrich Hegel – a German thinker of the early 19th century. Shortly I'll provide some more detail about Hegel and his work, but I want to begin with a justification of this particular orientation. Why build a course around a thinker who pre-dates, not only the recent era of machine learning, but the entire history of computation altogether?

---

The key text we'll be examining here is Hegel's *Phenomenology of Mind* (1807). For this course I will be using this text as a sort of *avant la lettre* account of how a *subject* – an entity that for the moment we will assume can exist in human, in machinic and perhaps in other situations – forms itself as a subject. In perhaps less obscure terms, how something like us learns to be as a conscious self. This text by Hegel occupies an important place in Western philosophy, and in some ways – as I hope to make clear – can be seen as one of the historical pivots around which questions of learning can be responded to. 

---

Controversially, this includes questions of machine learning. I will be arguing that Hegel's text makes the possibility of machine learning thinkable. I will also be arguing that present day machine learning fails, quite dramatically, to live up to the standard Hegel sets for it. In this failing, we can say that machines still do not learn. This is not the standard of consciousness, but rather something even more fundamental to learning – as I said earlier, how a subject *becomes* a subject. This involves creating a relationship between itself and its world, its history and future.  Hopefully this will become clearer as we progress. 

---

How does this connect with machine learning? Part of this course will examine the technical process by which machines learn – though I devote more time to the sibling course, *Introduction to Generative AI for Education*, for this work. Here we will spend more time thinking about the philosophical underpinnings of machine learning, and focus on one specific area that so far remains an open area of research in computer science: the problem of *continuous learning*. What is this problem? Let's imagine I sit down to *talk* to an AI agent such as ChatGPT. I notice that I am usually initiating a new conversation – though of course I can also choose to resume a prior conversation too. If I have paid for the subscription service and turned on the personalization feature, I notice also that the agent seems to know some details about me. Indeed, over time – if I connect the agent to my files and data – I also notice that this personalization seems to become more sophisticated and knowledgeable too.

---

However in another sense the system remains the same system it was at the point that its initial training was completed. Evidence of this appears in the common problem of cut-off dates – the point at which the content of the web was digested and fed into the machine learning algorithm. If we make an analogy to the human situation, it is as though this student had stopped acquiring any real new information after a certain point. Although it can pretend to know more, if I remove the connection to my data or personal history, the machine immediately forgets what it has known about me. The effect of this is not very obvious, because usually the training data cut-off is recent enough, and it is supplemented by Internet information. But were we to project ourselves a hundred years into the future, we'd have the strange sense of interacting with a mechanical ghost: its knowledge would not have been updated. 

---


There are efforts to develop continuous learning systems, though none are yet deployed in the major AI systems available to us. And this points immediately to one of the key fissures between human and machine learning. Try as we might, as human subjects we are unable to stop *experiencing* the world. In the same thought experiment, even if I was locked in a stimulus-free chamber for a period of time, if you asked me a question about what had happened in the world in the meantime I could not answer. But I would have experienced *something*. The machine does not – yet – do this. 

---


This focus on experience justifies the selection of Hegel's *Phenomenology* – really one of the most important documents of the idea of experience in the Western philosophical tradition. here isn't time to recapitulate the full complex story of the *Phenomenology*. We will be focussing on certain strategic elements of that story, which I will argue helps us to understand something about human processes of learning, and also how that relates to the machinic simulation of learning. Two of those elements involves the developmental and socialized nature of learning – aspects given much greater and more explicit treatment in pedagogical theory via the works of Piaget and Vygotsky. While Hegel's work does not discuss, for example, the stages of child development, in a certain sense the entire text of *Phenomenology* is an effort to understand the sequence or series of moves through which we come to a position of understanding and knowledge about the world and ourselves. In the first few lectures, we will be working through how Hegel sees this happening for an individual. In the latter part of the course, we will branch out to think of how learning is also social, and we will tackle – again with Hegel's support – different moments of socialized development too.

---

This discussion will not be directed, though, toward the simple aim of how machine learning is – and in a certain sense cannot ever be – equivalent to human learning. Our aim is instead more ambitious. Hegel was also a thinker of history, and understood history as also undergoing a series of developments. Without committing ourselves to Hegel's quite dogmatic understanding, we will seek to thematise how machine learning fits into a wider picture of human development and progress. What is – from a human learning perspective – the "end game" of machine learning? Where does it fit within our – usually implicit – account of why learning is important? This is not just a question of how we can use machine learning systems to supplement, accelerate and democratize how humans learn. It is rather a question of how we need to rewire both the content and the form of human learning in a world that is transforming dramatically – and which we need to insist upon still having some agency in that process of transformation. This will be what I hope is the practical payoff for an otherwise arduous conceptual journey through the world of Hegelian philosophy.



[[stochastic_society]]


[[2+2=5]]


Authors:

[@hegel2025phenomenology; @kojeve1980introduction; @hyppolite1974genesis; @houlgate2012hegel; @heidegger1988hegel; @pippin2010hegel; @hegel2014science; @vzivzek2020hegel]