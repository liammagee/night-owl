# Machine Learning and Human Learning



## Readings

None for Week 1!



## Assessment

Comment on any of the following questions:
 - What does it mean to learn? How do you know when human learning happens: in the classroom, workplace or life?
 - Machine learning is clearly inspired by human learning. In your use of AI to date, how would you describe what it has learned (memorized, regurgitated, etc)? When AI gets things wrong, how are its errors different (or similar) to human mistakes?
 - I have introduced the concept of "synthesis" to describe the similarities and differences between machine and human learning.  What are your views?


## Structure

1. Outline of the Course - Circular Structure
  - [[lecture-concepts]]
2. Weekly Format
  - Mix of theory (lectures) / practice / discussion
3. Assessments  
4. A previous version of this course ran in 2023 and 2024: [[2023-Course]]
5. Lens: Hegelian Philosophy. Why Hegel?
  - basic hypothesis: machine learning is rooted in 18th century empiricism (more data = more truth)
  - What does Hegel offer? One way to think about learning as *nonlinear* (structured / dialectical / involving negation etc). This is important for later pedagogical theorists such as Dewey, Vygotsky and Piaget – Hegel's influence on these thinkers (and their general critique of mechanical learning will become clear).
  - This will hopefully become clear! We start with the idea of synthesis between machine learning and human learning, then go down several rabbit holes, before returning, in Week 8, to a modified idea of synthesis.
6. 8 Weeks = 8 Concepts
7. Discussion



## Overview


Welcome to Machine Learning and Human Learning!

In this course we'll be exploring these two related – but also very distinct – ideas. This week I'll provide an overview of the course, readings, approach and assessment. I'll also be introducing the work of Hegel, an Enlightenment-era German philosopher who will supply an important lens onto many of the questions posed by machines which purport to learn. 

We'll also have a general open discussion about machine learning and human learning: what unites them, and what distinguishes them. In true dialectical fashion, we will then think about what possible synthesis we might see between these two modalities of learning. Part of this discussion will involve, naturally enough, a machine that will be joining us – GPT-5 – to share its views.



---


## Modalities of Learning 

This course presents what I will be calling a *critical* outline of machine learning and human learning. I will also be referring to both kinds of learning as "modalities" – species, if you like, of the general process of learning. This form may rub some of you the wrong way - you may want to insist upon machine learning not only as distinct but also as derivative, an imitation or copy, and perhaps not even a *good* copy, of human learning. We will of course be returning to such ideas in the course itself.  




---

## Comparative Analysis of Human and Machine Learning

As the title also suggests, any critical inquiry involves a process of both comparison and contrast: a consideration of what is common to both both modalities, and what distinguishes them. This process is something that, for this course, I want to approach in a philosophical way. What I mean by this is that, alongside texts from areas of child psychology, linguistics and computer science, I want us to investigate the idea of "learning" through a fundamentally *philosophical* type of inquiry. This I think leads us to think about less about learning as a set of features that pertain to humans, machines or both, and more about learning as itself a process that ranges across a set of common distinctions: between human and machine, but also between individual and society, between child and adult, and so on. It will also help us, I hope, to think about learning as something cooperative, involving both social and technical, or what are sometimes thought as sociotechnical systems, or in the vocabulary of Mary Kalantzis and Bill Cope, as cyber-social systems. I've coined the term "symbiotic pedagogy" to describe this kind of cooperation. Finally, we might conclude by developing some normative claims: about what constitutes legitimate as opposed to illegitimate forms of machine learning and machine learning.


---



---

The presentation of the course will be unusual. I've asked that we allocate up to 2 hours per week for seminars. 
 I plan to develop and deliver the lecture material as a series of short "pod" style lectures

 offline, and then use the weekly hour allocated to us to discuss both that material and associated readings. This will in some ways add more labor and time to the course, but also allow us to plumb more deeply into a complex topic that ranges across disciplinary fields.

---

For this year (at least), I plan to develop this philosophical lens around the work of a specific philosopher, Georg Friedrich Hegel – a German thinker of the early 19th century. Shortly I'll provide some more detail about Hegel and his work, but I want to begin with a justification of this particular orientation. Why build a course around a thinker who pre-dates, not only the recent era of machine learning, but the entire history of computation altogether?

---

The key text we'll be examining here is Hegel's *Phenomenology of Mind* (1807). For this course I will be using this text as a sort of *avant la lettre* account of how a *subject* – an entity that for the moment we will assume can exist in human, in machinic and perhaps in other situations – forms itself as a subject. In perhaps less obscure terms, how something like us learns to be as a conscious self. This text by Hegel occupies an important place in Western philosophy, and in some ways – as I hope to make clear – can be seen as one of the historical pivots around which questions of learning can be responded to. 

---

Controversially, this includes questions of machine learning. I will be arguing that Hegel's text makes the possibility of machine learning thinkable. I will also be arguing that present day machine learning fails, quite dramatically, to live up to the standard Hegel sets for it. In this failing, we can say that machines still do not learn. This is not the standard of consciousness, but rather something even more fundamental to learning – as I said earlier, how a subject *becomes* a subject. This involves creating a relationship between itself and its world, its history and future.  Hopefully this will become clearer as we progress. 

---

How does this connect with machine learning? Part of this course will examine the technical process by which machines learn – though I devote more time to the sibling course, *Introduction to Generative AI for Education*, for this work. Here we will spend more time thinking about the philosophical underpinnings of machine learning, and focus on one specific area that so far remains an open area of research in computer science: the problem of *continuous learning*. What is this problem? Let's imagine I sit down to *talk* to an AI agent such as ChatGPT. I notice that I am usually initiating a new conversation – though of course I can also choose to resume a prior conversation too. If I have paid for the subscription service and turned on the personalization feature, I notice also that the agent seems to know some details about me. Indeed, over time – if I connect the agent to my files and data – I also notice that this personalization seems to become more sophisticated and knowledgeable too.

---

However in another sense the system remains the same system it was at the point that its initial training was completed. Evidence of this appears in the common problem of cut-off dates – the point at which the content of the web was digested and fed into the machine learning algorithm. If we make an analogy to the human situation, it is as though this student had stopped acquiring any real new information after a certain point. Although it can pretend to know more, if I remove the connection to my data or personal history, the machine immediately forgets what it has known about me. The effect of this is not very obvious, because usually the training data cut-off is recent enough, and it is supplemented by Internet information. But were we to project ourselves a hundred years into the future, we'd have the strange sense of interacting with a mechanical ghost: its knowledge would not have been updated. 

---

There are efforts to develop continuous learning systems, though none are yet deployed in the major AI systems available to us. And this points immediately to one of the key fissures between human and machine learning. Try as we might, as human subjects we are unable to stop *experiencing* the world. In the same thought experiment, even if I was locked in a stimulus-free chamber for a period of time, if you asked me a question about what had happened in the world in the meantime I could not answer. But I would have experienced *something*. The machine does not – yet – do this. 

---


This focus on experience justifies the selection of Hegel's *Phenomenology* – really one of the most important documents of the idea of experience in the Western philosophical tradition. here isn't time to recapitulate the full complex story of the *Phenomenology*. We will be focussing on certain strategic elements of that story, which I will argue helps us to understand something about human processes of learning, and also how that relates to the machinic simulation of learning. Two of those elements involves the developmental and socialized nature of learning – aspects given much greater and more explicit treatment in pedagogical theory via the works of Piaget and Vygotsky. While Hegel's work does not discuss, for example, the stages of child development, in a certain sense the entire text of *Phenomenology* is an effort to understand the sequence or series of moves through which we come to a position of understanding and knowledge about the world and ourselves. In the first few lectures, we will be working through how Hegel sees this happening for an individual. In the latter part of the course, we will branch out to think of how learning is also social, and we will tackle – again with Hegel's support – different moments of socialized development too.

---

This discussion will not be directed, though, toward the simple aim of how machine learning is – and in a certain sense cannot ever be – equivalent to human learning. Our aim is instead more ambitious. Hegel was also a thinker of history, and understood history as also undergoing a series of developments. Without committing ourselves to Hegel's quite dogmatic understanding, we will seek to thematise how machine learning fits into a wider picture of human development and progress. What is – from a human learning perspective – the "end game" of machine learning? Where does it fit within our – usually implicit – account of why learning is important? This is not just a question of how we can use machine learning systems to supplement, accelerate and democratize how humans learn. It is rather a question of how we need to rewire both the content and the form of human learning in a world that is transforming dramatically – and which we need to insist upon still having some agency in that process of transformation. This will be what I hope is the practical payoff for an otherwise arduous conceptual journey through the world of Hegelian philosophy.





Authors:

[@hegel2025phenomenology; @kojeve1980introduction; @hyppolite1974genesis; @houlgate2012hegel; @heidegger1988hegel; @pippin2010hegel; @hegel2014science; @vzivzek2020hegel]