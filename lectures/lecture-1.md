

# <a id="machine-learning-and-human-learning"></a>Machine Learning and Human Learning



## <a id="readings"></a>Readings

None for Week 1!



## <a id="assessment"></a>Assessment


Comment on any of the following questions:
 - What does it mean to learn? How do you know when human learning happens: in the classroom, workplace or life?
 - Machine learning is clearly inspired by human learning. In your use of AI to date, how would you describe what it has learned (memorized, regurgitated, etc)? When AI gets things wrong, how are its errors different (or similar) to human mistakes?
 - I have introduced the concept of "synthesis" to describe the similarities and differences between machine and human learning.  What are your views? Do the similarities outweigh the differences, or vice versa?


## <a id="structure"></a>Structure

1. Introduction to the Course
2. Weekly Format
  - Mix of theory (lectures) / practice / discussion
3. Assessments  
4. A previous version of this course ran in 2023 and 2024: [[2023-Course]]
5. Circular Structure
  - [[lecture-concepts]]
6. Lens: Hegelian Philosophy. Why Hegel?
  - basic hypothesis: machine learning is rooted in 18th century empiricism (more data = more truth)
  - What does Hegel offer? One way to think about learning as *nonlinear* (structured / dialectical / involving negation etc). This is important for later pedagogical theorists such as Dewey, Vygotsky and Piaget – Hegel's influence on these thinkers (and their general critique of mechanical learning will become clear).
  - This will hopefully become clear! We start with the idea of synthesis between machine learning and human learning, then go down several rabbit holes, before returning, in Week 8, to a modified idea of synthesis.
7. 8 Weeks = 8 Concepts
8. Discussion



## <a id="overview"></a>Overview


Welcome to Machine Learning and Human Learning!

In this course we'll be exploring these two related – but also very distinct – ideas. This week I'll provide an overview of the course, readings, approach and assessment. I'll also be introducing the work of Hegel, an Enlightenment-era German philosopher who will supply an important lens onto many of the questions posed by this new era of machine learning. 

We'll also have a general open discussion about machine learning and human learning: what unites them, and what distinguishes them. In true dialectical fashion - a term we will get used to as we read Hegel – we will then think about what possible synthesis we might see between these two ways of learning. Part of this discussion will involve, naturally enough, a machine that will be joining us – GPT-5 – to share its views.



---

## <a id="main-lecture"></a>Welcome to Machine Learning and Human Learning!

---

### Synthesis

We have entered an era in which our ideas about learning are changing, and perhaps have already changed fundamentally. The history of technological aids, from the writing stylus to the abacus, calculator, Internet and smartphone, has always shaped how we exteriorize our memory, and in turn re-interiorize during recollection. Machines have, in other words, always been central to how we humans learn. 

But today we also talk about machines learning how to do things themselves. Most obviously this happens in the fields of AI, and more specifically, of Generative AI. These machines now learn from *us* – from the traces of us we leave in data stored on the Internet. Machines learn from us; and from these new machines, we also learn differently. Asking ChatGPT to create a new recipe is different, we could say, from asking a calculator to add two numbers or even asking Google to find a recipe. We will explore this difference in the course, but for now we can note that we have entered a period in which "learning" comes to be applied to machines as well as humans, and that this learning, in both cases, depends upon the other.

We can now speak in various ways about this much closer relationship we share with machines. We can speak of socio-technical systems; of cyborgian creatures (Harraway); of cyber-social systems (Kalantzis Cope); and of compound terms like 'technosymbiosis' (Katherine Hayles) or a term I'll be using, in the context of learning, 'symbiotic pedagogy'. But the wider concept we'll be working with this week - and returning to, as we'll see - is that of *synthesis*. *Synthesis* will describe how both the similarities and differences between machine and human learning come together in our present moment.

Through the course we will be studying this relationship in a number of ways. Later I'll talk through the organization of the course materials. 

---

## Administration


### Weekly seminars. 

My preference is for these to be two hours (5:30 - 7:30), with a brief break. I'm flexible here though. Essentially we have a lot we can present, discuss and practice. My ideal here is that I will present 2 x 15 minute lecture pods, after which we will have a mix of discussion and practice with AI models.

But the course hours are much fewer than this. What do people think? Otherwise we can truncate to 90 or even 60 minutes.

### Assessment

The course will use CGScholar – a platform I think most of you will be familiar with? Assessments will be divided between:

1. Weekly discussion and commentary in CGScholar (formative learning!)
2. An individual curriculum, learning guide or conference presentation outline (summative learning!). This will be your choice, but could be either of:
  a. Learning materials designed for machines, describing some facet of human culture
  b. or Learning materials designed for humans, describing some facet of machine "experience"

### Previous course

A previous version of this course ran in 2023 and 2024: [[2023-Course]]

Despite this having the same name as that course, it is very different. And I would encourage people to look back to Bill and Mary's earlier course, and especially their videos, which are excellent. As you will probably gather, I have a quite different take. I would say by going back and forth, you might get the best of both worlds. Keep the link to the course handy, and feel free to consult both videos and readings.



---

### Our Approach in 2025



So what distinguishes our approach in 2025? The first and biggest difference will be my reliance on the work of a early 19th century German Philosopher, Georg Wilhelm Friedrich Hegel. 

Why Hegel? Why build a course on machine learning around a thinker who pre-dates, not only the recent era of machine learning, but the entire history of computation altogether?

Let me give a few reasons.

First, I will be arguing one of the present limitations of machine learning is that it is stuck in a period of thinking about learning: the 18th century. According to the philosophy of the period – and I am of course simplifying here – the human mind was a blank slate that needed to be filled up with facts. Learning was a comparatively simple process of *accumulation*. Just as life itself is the experience of a sequence of moments, each of which is compared to other moments, so learning is the acquisition of experience that are recorded in the mind. 

This, as we'll review, is a form of the *empiricism* that underpins our current paradigm of machine learning. Now Hegel – as we'll also see – represents a profound challenge to the empirical tradition. His account of experience is not simply accumulative –– it is *dialectical*, which presumes that new experiences can sometimes *negate* those that they succeed. Learning proceeds, in other words, in a series of developmental stages, each of which involves some kind of realization or learning moment which can sometimes refute a past moment. Although, at least in Hegel's account, both past and present moment, even if they stand in contradiction, can be reconciled in a process of *synthesis*, constituting in turn a future moment which initiates the whole process all over again. Some of you might hear echoes here of later theorists of learning like Jean Piaget, who also supposed learning proceeded in development stages.

In addition – and here is the second reason – Hegel's account is rooted in our experience of *others*. In a way that prempts another learning theorist, Vygotsky, Hegel's account of human experience also involves a specific development from consciousness to self-consciousness. Ironically, our awareness of ourselves is closely connected to our awareness of other selves who are not our self - other people, in other words. This awareness means our experience and learning is *social*, conditioned and mediated by others. Now it is an open question as to whether machines are said to be social at all, but certainly not, as we'll see, in the sense that Hegel means. 

The third reason relates less to Hegel's direct views about learning, and more to his understanding of history. Within the Western tradition of philosophy, Hegel is the first and central philosopher of history – in the sense that he discusses history as something like a wider social and collective learning project. History moreover has a tendency or direction: it moves towards gradual realization or recognition, what Hegel terms, grandiosely, as the Absolute Idea or Absolute Knowledge. Outside religion, perhaps few today would agree strongly with Hegel that history follows a determinate path. However, with the arrival of AI – and certainly with much of the hype that comes with it – we are also forced to confront a series of questions: where are we going with AI? Will we arrive at a singularity, when AI becomes smarter than humans? And what skills do future human learners need to navigate this particular historical moment? Hegel doesn't answer this question, but – especially in his confrontation with the major events of his own time, including the French Revolution – he is already opening a way for consideration of our position within a wider time and history. 

And finally, Hegel occupies an unusual position himself in the recent history of philosophy. Long regarded – for reasons we shall see, as we begin to look at some of his text – as an obscure and complex thinker without much value to mainstream philosophy, he has become central in recent decades to debates about language, norms and consciousness. Robert Brandom, a prominent American philosopher, has written for example an 800 page volume called *A Spirit of Trust: A Reading of Hegel's Phenomenology of Spirit*. Brandom, among others, is an important thinker in his own right about AI, and this suggests Hegel provides us with good background – if we want it – to contemporary discussions about learning and language. 


--- 

## Organization of the Course


The course is structured over eight weeks, and each week introduces and discusses a new concept. 

1. **Synthesis** This is the introduction and overview we are doing today. 
2. Experience
 - Next week we'll be looking at the concept of Experience. This is a crucial idea in Hegel's **Phenomenology of Spirit**, and constitutes the single largest implicit criticism of non-human learning. We will examine how Hegel unpacks this idea, and contrast it with other ideas of experience (e.g. Locke) that might be closer to what we see of machinic "experience". We will also discuss the relationship of experience to learning, consciousness, perception and memory. 
3. Attention
  - Following that, we will focus on the idea of attention. This is an idea that spans neuroscience, psychology, computer science, philosophy and media studies. We'll examine a key text in the development of machine learning, "Attention is All you Need". But we will also think about how attention is important for human learning. And we will look at recent critical studies of attention and what has become known as the Attention Economy.
4. Recognition  
 - Another key Hegelian idea, this week we will examine how *recognition* connects individual  learning to our relation to others - to, in other words, a social process. We'll discuss here Vygotsky's theory of human learning, and also examine ways machines could be considered as "recognizing" us.   
5. Consciousness (Self/Other/Un/Non)
The early parts of Phenomenology of Spirit is dominated by the ideas of Consciousness and Self-consciousness. We'll explore how these relate to Experience, Attention and Recognition (and whether indeed they "synthesize" these earlier ideas). We'll explore also later ideas of the Unconscious (Freud) and Nonconscious Cognition (Katherine Hayles). This leads us naturally to an obvious question: can machines be conscious? If not, can they be unconscious? 
6. Alignment
Alignment is a "vogue" term in machine learning, and describes the process of aligning machines to human values and interests. One technical process for doing this is RLHF – reinforcement learning from human feedback.  This relates closely to ideas of "norms". As opposed to rules or laws, norms describe often implied values that condition our practices, including our speaking practices. So "alignment" also can describe human learning – aligning ourselves with others. And increasingly today, we can also think of humans aligning themselves with machine values, especially in pedagogical settings.  
7. Critique 
"Critique" then brings us to what happens when alignment, one way or another, fails: when technology, in other words, fails to meet the wider social standards we set for it. Critique is another keyword also in the Hegelian nomenclature - it comes famously from Kant, for whom "Critique" is the method for understanding how "pure" (rational, scientific), "practical" (applied, moral) and "judgemental" (aesthetic) reasoning can happen. Here we will look at how Critical AI has been responding to AI - and look in turn at how AI works itself as a tool for, as well as of, critique.  
8. Synthesis: Technosymbiosis
Finally, we return to where we started: with the concept of synthesis. However – just like a Hegelian process of argument – our original concept is now modified and inflected by the other concepts and materials we've encountered. In particular we are in a position to understand N. Katherine Hayles' idea of "technosymbiosis" – the combining of technology and life – a synthesis that also incorporates earlier ideas of experience, attention, recognition, consciousness, alignment and critique. 



--- 

## A word on software....

Now some of you may have seen that I'm using some unusual software to do this presentation – and I'll be using it for the rest of this course. You'll see it's called "Hegel Pedagogy AI", and indeed I've written this software – or more exactly, I've prompted Claude to write the software. I used to be a software developer, and I've always wanted something that could convert notes into a presentation. So I asked Claude to write this "note converter" for this course. It may change week-to-week, and if I think it is useful for anyone other than myself, I'll release it.

But more to the point, I want people also to experiment with how these AI tools also write software. In fact this might be one of the sweet spots of AI today – as a software writing assistant. For the right applications, it has reduced the technical demands of users to nearly zero. One practical effect is that the key skills needed for so-called "vibe coding" are no longer deep algorithmic knowledge, but rather design and writing – specifically, how to talk to machines to get the results you want. Management, in other words, and not far removed from teaching. A new kind of human human learning is required to make use of these new kinds of learning machines, and to offset some of the conceptual terrain of this course, we'll also be practicing how to write software.

--- 

## Introductions

Finally, let's introduce ourselves...


---

Authors:

[@hegel2025phenomenology; @kojeve1980introduction; @hyppolite1974genesis; @houlgate2012hegel; @heidegger1988hegel; @pippin2010hegel; @hegel2014science; @vzivzek2020hegel]