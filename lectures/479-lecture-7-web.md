
## Bitter Lessons, Stochastic Parrots, Errant Agents: From Criticism to Immanent Critique?



As we move toward the conclusion of the course, this week we follow on from discussions of alignment to the related concept of critique.

We start with two recent examples of what has been termed "critical AI studies". Following the now-famous "Stochastic Parrots" paper (Bender et al. 2021), in these two readings Goodlad and Stone and Gebru and Torres administer highly critical readings of current tendencies in AI. 

From there I have suggested two voices that are internal to developments in AI - in fact, two key figures in the development of neural networks and reinforcement learning. In the first of these, Yann LeCun (Chief Scientist at Meta) argues that LLMs are an effective technology - but a deadline with respect to the pursuit of Artificial General Intelligence. In its place, he advocates a machine learning architecture modelled much more directly on human neurology (see the Supplementary Readings for details). 

In the second video, Richard Sutton suggests that LLMs face limits for similar reasons. But his language almost seems to parallel the very language Hegel uses two centuries earlier: machines lack *experience* and *goals* (a proxy for what Hegel may mean by *desire*).

All four represent examples of *criticism* of AI. But this week I want to push this direction further - into what has been termed "immanent critique". I've included a recent explanatory article by Titus Stahl, which unpacks the concept along with its history. Unsurprisingly, as I'll unpack in this week's lecture - and as we've already seen in earlier weeks on *Experience* and *Recognition* – that history goes back to Hegel (and to Kant before him). 

We might, if we are to follow Hegel's suggestions, seek to develop a similarly immanent critique of artificial intelligence. But I haven't been able to find one! So I have include in the Appendix below a fragment of a conversation with ChatGPT. 

As always, work through what you can - but do have a look at the article at Immanent Critique, even if only to see how Hegel's work continues to be discussed today.




### Readings & Videos

[Beyond Chatbot-K: On Large Language Models, “Generative AI,” and Rise of Chatbots—An Introduction...](https://read.dukeupress.edu/critical-ai/article/doi/10.1215/2834703X-11205147/390862/Beyond-Chatbot-K-On-Large-Language-Models)

[View of The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intell...](https://firstmonday.org/ojs/index.php/fm/article/view/13636/11599)


[Richard Sutton – Father of RL thinks LLMs are a dead end](https://www.dwarkesh.com/p/richard-sutton)


[Yann LeCun: We Won't Reach AGI By Scaling Up LLMS - YouTube](https://www.youtube.com/watch?v=4__gg83s_Do)

Stahl, T. (2013). What is immanent critique?. Available at SSRN 2357957. https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=2357957


### Supplementary Critical Readings

[[2410.18417] Large Language Models Reflect the Ideology of their Creators](https://arxiv.org/abs/2410.18417)

[The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)


[Cultural Red Teaming: ARRG! and Creative Misuse of AI Systems | Critical AI | Duke University Press](https://read.dukeupress.edu/critical-ai/article/doi/10.1215/2834703X-11700228/401274/Cultural-Red-Teaming-ARRG-and-Creative-Misuse-of)

[Pluralistic: The real (economic) AI apocalypse is nigh (27 Sep 2025) &#8211; Pluralistic: Daily l...](https://pluralistic.net/2025/09/27/econopocalypse/#subprime-intelligence)

LeCun, Y. (2022). A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27. Open Review, 62(1), 1-62. https://openreview.net/pdf?id=BZ5a1r-kVsf

### Questions

1. This week's readings are roughly divided between two camps: those external to the wider AI enterprise, who are critical of that project; and those who, on the contrary, are fundamental to that enterprise but seek to move it away from its (LLM-obsessed!) path towards something more experiential. Which of these two camps are you more sympathetic toward? Or do you think both are too critical? Or neither is critical enough? Discuss!

2. "Immanent critique" is an important idea in the history of critical theory. Does it resonate with us today? Criticism can sometimes seem mired in the adoption of irreconcilable – and dogmatic - standpoints. Can we find ways to develop critique that is more compelling, because it accounts for its own possibility? Or is this an academic conceit that ultimately will have little purchase in practical deliberations over AI?

3. On a more practical note: As teachers and curriculum designers, there is a huge amount to learn, synthesize and broadcast on the topic of AI. What should we be teaching about AI? How important is, as Goodlad and Stone (2024) put it, "critical AI literacy" today? And what topics must it emphasize?

<!--
3. Thinking back to earlier weeks – on experience, recognition, attention , consciousness and alignment – how close are LLMs to become agents of critique themselves? Are they ready to play leadership roles as decision makers - as teachers, business managers, politicians, coaches, therapists? If not, what aspects of **critique** do we wish to hold on to as uniquely or distinctly human?
-->


### Appendix:

[ChatGPT - Hegel immanent critique discussion](https://chatgpt.com/share/68dd9858-08b0-8007-b33d-140912a39163)