<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>temp_html_pandoc_export</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
</head>
<body>
<h1 id="human-and-machine-learning">Human and Machine Learning</h1>
<h2 id="overview">Overview</h2>
<hr />
<h2 id="comparative-analysis-of-human-and-machine-learning">Comparative
Analysis of Human and Machine Learning</h2>
<ul>
<li>The course provides an overview of both human and machine
learning.</li>
<li>It aims to identify similarities between human and machine learning
processes.</li>
<li>It emphasizes the distinguishing factors between human and machine
learning.</li>
<li>This course employs a comparative and contrastive approach towards
understanding learning processes.</li>
</ul>
<pre class="notes"><code>This course presents an outline of human and machine learning. As the title suggests, this involves a process of comparison and contrast: what is common to both human and machine learning, and what distinguishes them. </code></pre>
<hr />
<h2 id="philosophy">philosophy</h2>
<p>This process is something that, for this course, I want to approach
in a philosophical way. What I mean by this is that, alongside texts
from areas of child psychology, linguistics and computer science, I want
us to investigate the idea of “learning” through a fundamentally
<em>philosophical</em> type of inquiry. This I think leads us to think
about less about learning as a set of features that pertain to humans,
machines or both, and more about learning as itself a process that
ranges across a set of common distinctions: between human and machine,
but also between individual and society, between child and adult, and so
on. It will also help us, I hope, to think about learning as something
cooperative, involving both social and technical, or what are sometimes
thought as sociotechnical systems. I’ve coined the term “symbiotic
pedagogy” to describe this kind of cooperation. Finally, we might
conclude by developing some normative claims: about what constitutes
legitimate as opposed to illegitimate forms of human and machine
learning.</p>
<hr />
<p>The presentation of the course will be unusual. I plan to develop and
deliver the lecture material offline, and then use the weekly hour
allocated to us to discuss both that material and associated readings.
This will in some ways add more labor and time to the course, but also
allow us to plumb more deeply into a complex topic that ranges across
disciplinary fields.</p>
<hr />
<p>For this year (at least), I plan to develop this philosophical lens
around the work of a specific philosopher, Georg Friedrich Hegel – a
German thinker of the early 19th century. Shortly I’ll provide some more
detail about Hegel and his work, but I want to begin with a
justification of this particular orientation. Why build a course around
a thinker who pre-dates, not only the recent era of machine learning,
but the entire history of computation altogether?</p>
<hr />
<p>The key text we’ll be examining here is Hegel’s <em>Phenomenology of
Mind</em> (1807). For this course I will be using this text as a sort of
<em>avant la lettre</em> account of how a <em>subject</em> – an entity
that for the moment we will assume can exist in human, in machinic and
perhaps in other situations – forms itself as a subject. In perhaps less
obscure terms, how something like us learns to be as a conscious self.
This text by Hegel occupies an important place in Western philosophy,
and in some ways – as I hope to make clear – can be seen as one of the
historical pivots around which questions of learning can be responded
to.</p>
<hr />
<p>Controversially, this includes questions of machine learning. I will
be arguing that Hegel’s text makes the possibility of machine learning
thinkable. I will also be arguing that present day machine learning
fails, quite dramatically, to live up to the standard Hegel sets for it.
In this failing, we can say that machines still do not learn. This is
not the standard of consciousness, but rather something even more
fundamental to learning – as I said earlier, how a subject
<em>becomes</em> a subject. This involves creating a relationship
between itself and its world, its history and future. Hopefully this
will become clearer as we progress.</p>
<hr />
<p>How does this connect with machine learning? Part of this course will
examine the technical process by which machines learn – though I devote
more time to the sibling course, <em>Introduction to Generative AI for
Education</em>, for this work. Here we will spend more time thinking
about the philosophical underpinnings of machine learning, and focus on
one specific area that so far remains an open area of research in
computer science: the problem of <em>continuous learning</em>. What is
this problem? Let’s imagine I sit down to <em>talk</em> to an AI agent
such as ChatGPT. I notice that I am usually initiating a new
conversation – though of course I can also choose to resume a prior
conversation too. If I have paid for the subscription service and turned
on the personalization feature, I notice also that the agent seems to
know some details about me. Indeed, over time – if I connect the agent
to my files and data – I also notice that this personalization seems to
become more sophisticated and knowledgeable too.</p>
<hr />
<p>However in another sense the system remains the same system it was at
the point that its initial training was completed. Evidence of this
appears in the common problem of cut-off dates – the point at which the
content of the web was digested and fed into the machine learning
algorithm. If we make an analogy to the human situation, it is as though
this student had stopped acquiring any real new information after a
certain point. Although it can pretend to know more, if I remove the
connection to my data or personal history, the machine immediately
forgets what it has known about me. The effect of this is not very
obvious, because usually the training data cut-off is recent enough, and
it is supplemented by Internet information. But were we to project
ourselves a hundred years into the future, we’d have the strange sense
of interacting with a mechanical ghost: its knowledge would not have
been updated.</p>
<hr />
<p>There are efforts to develop continuous learning systems, though none
are yet deployed in the major AI systems available to us. And this
points immediately to one of the key fissures between human and machine
learning. Try as we might, as human subjects we are unable to stop
<em>experiencing</em> the world. In the same thought experiment, even if
I was locked in a stimulus-free chamber for a period of time, if you
asked me a question about what had happened in the world in the meantime
I could not answer. But I would have experienced <em>something</em>. The
machine does not – yet – do this.</p>
<hr />
<p>This focus on experience justifies the selection of Hegel’s
<em>Phenomenology</em> – really one of the most important documents of
the idea of experience in the Western philosophical tradition. here
isn’t time to recapitulate the full complex story of the
<em>Phenomenology</em>. We will be focussing on certain strategic
elements of that story, which I will argue helps us to understand
something about human processes of learning, and also how that relates
to the machinic simulation of learning. Two of those elements involves
the developmental and socialized nature of learning – aspects given much
greater and more explicit treatment in pedagogical theory via the works
of Piaget and Vygotsky. While Hegel’s work does not discuss, for
example, the stages of child development, in a certain sense the entire
text of <em>Phenomenology</em> is an effort to understand the sequence
or series of moves through which we come to a position of understanding
and knowledge about the world and ourselves. In the first few lectures,
we will be working through how Hegel sees this happening for an
individual. In the latter part of the course, we will branch out to
think of how learning is also social, and we will tackle – again with
Hegel’s support – different moments of socialized development too.</p>
<hr />
<p>This discussion will not be directed, though, toward the simple aim
of how machine learning is – and in a certain sense cannot ever be –
equivalent to human learning. Our aim is instead more ambitious. Hegel
was also a thinker of history, and understood history as also undergoing
a series of developments. Without committing ourselves to Hegel’s quite
dogmatic understanding, we will seek to thematise how machine learning
fits into a wider picture of human development and progress. What is –
from a human learning perspective – the “end game” of machine learning?
Where does it fit within our – usually implicit – account of why
learning is important? This is not just a question of how we can use
machine learning systems to supplement, accelerate and democratize how
humans learn. It is rather a question of how we need to rewire both the
content and the form of human learning in a world that is transforming
dramatically – and which we need to insist upon still having some agency
in that process of transformation. This will be what I hope is the
practical payoff for an otherwise arduous conceptual journey through the
world of Hegelian philosophy.</p>
<p>[[stochastic_society]]</p>
<p>[[2+2=5]]</p>
<p>Authors:</p>
<p><span class="citation"
data-cites="hegel2025phenomenology kojeve1980introduction hyppolite1974genesis houlgate2012hegel heidegger1988hegel pippin2010hegel hegel2014science vzivzek2020hegel">(G.
W. Hegel 2025; Kojève 1980; Hyppolite 1974; Houlgate 2012; Heidegger
1988; Pippin 2010; G. W. F. Hegel 2014; Žižek 2020)</span></p>
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" role="list">
<div id="ref-hegel2025phenomenology" class="csl-entry" role="listitem">
Hegel, Georg WF. 2025. <em>The Phenomenology of Spirit (the
Phenomenology of Mind)</em>. Rare Treasure Editions.
</div>
<div id="ref-hegel2014science" class="csl-entry" role="listitem">
Hegel, Georg Wilhelm Friedrich. 2014. <em>Science of Logic</em>.
Routledge.
</div>
<div id="ref-heidegger1988hegel" class="csl-entry" role="listitem">
Heidegger, Martin. 1988. <em>Hegel’s Phenomenology of Spirit</em>.
Indiana university press.
</div>
<div id="ref-houlgate2012hegel" class="csl-entry" role="listitem">
Houlgate, Stephen. 2012. <span>“Hegel’s ’Phenomenology of
Spirit’.”</span>
</div>
<div id="ref-hyppolite1974genesis" class="csl-entry" role="listitem">
Hyppolite, Jean. 1974. <em>Genesis and Structure of Hegel’s"
Phenomenology of Spirit"</em>. Northwestern University Press.
</div>
<div id="ref-kojeve1980introduction" class="csl-entry" role="listitem">
Kojève, Alexandre. 1980. <em>Introduction to the Reading of Hegel</em>.
Cornell University Press.
</div>
<div id="ref-pippin2010hegel" class="csl-entry" role="listitem">
Pippin, Robert B. 2010. <em>Hegel on Self-Consciousness: Desire and
Death in the Phenomenology of Spirit</em>. Princeton University Press.
</div>
<div id="ref-vzivzek2020hegel" class="csl-entry" role="listitem">
Žižek, Slavoj. 2020. <span>“Hegel in a Wired Brain.”</span>
</div>
</div>
</body>
</html>
