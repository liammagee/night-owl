
## Hegel's Revenge: The Return of the *Grand Récit*?

Perhaps the major intellectual movement in the postwar period, postmodernist (and related poststructuralist) thought argued against what one prominent theorist, Jean Francois Lyotard, termed the *Grand Récit*: the idea of a grand narrative governing human society and development. For Lyotard, and for many others, grand narratives died with the second world war, since no major project for humanity could any longer be sustained. Instead, we would be faced with competing *small narratives*, reflecting the desires of communities and perhaps nations, but not of humanity as a whole. In intellectual terms, we may have specific disciplinary projects and agendas, but not a grand unifying theory capable of tying, for instance, the sciences and the humanities together. Knowledge was to be fractured, partial, no longer held together by any organization or structure (hence, in at least one of its senses, "poststructural"). 

This argument was directed towards the major proponents of "big picture" thinking: Sartre, Freud, Marx among them. But the largest target was likely Hegel, who more than any other projected a "big picture" and grand narrative in texts like *The Phenomenology of Spirit". Via the dialectical process, knowledge was able to move beyond its disciplinary and temporary constraints, and so to become "Absolute". Spirit, in some very general sense, learned its way across history towards this grand destination.

Can we still hear echoes of Hegel today? Certainly those promoting AI do so partly on grounds that the limits of knowledge might be overcome. Maths and science can be accelerated. Texts and media in different languages can be translated. Differences in perspectives can be explained. Last week I suggested - perhaps a little tongue-in-cheek - that Hegel was a transhumanist. But does AI now promise a return to the possibilities that Hegel, along with other Enlightenment thinkers, demarcated? 

To round out our course on machine and human learning, we examine the last (as well as the first) of our concepts: *Synthesis*. We explore how machines and humans, in varied ways, might be or become synthesized, and consider what this means for the stories we tell about our futures. 

Last week we saw how critical AI – a discipline originating within the humanities – emphasized its negative effects. But critical scholarship can also point the way forward. This week's readings – from Rosa Braidoti, N Katherine Hayles, Yuk Hui, and Mary Kalantzis and Bill Cope – emphasize alternative visions for how AI might help us to construct posthuman, technosymbiotic, technodiverse, and cybersocial feedback loops that promote collective human as much as machine learning. If these paths do not tend toward historicist goals like Absolute Knowledge, then perhaps they also avoid yoking learning to the demands of servitude. 

I have also included a reading from Francis Fukuyama, a neo-Hegelian scholar who argued that history had already ended with the end of the Cold War. In keeping with the wide ambitions of this final week, we might ask whether AI has restarted history again (or whether it ever truly ended)?

Our final step for the course will be to compile a curriculum and syllabus. We will spend some time in class transferring this theoretical discussion into the practical work of the final assignment.



### Readings

Braidotti, R. (2025). Posthuman ethics for AI. Journal of Bioethical Inquiry, 1-5. https://link.springer.com/article/10.1007/s11673-025-10447-2

Hayles, N. K. (2023). Figuring (Out) Our Relations to AI. Feminist AI: Critical perspectives on algorithms, data, and intelligent machines, 1. https://academic.oup.com/book/55103/chapter/423909701

Birnbaum, Daniel, and Yuk Hui. “Yuk Hui in Conversation with Daniel Birnbaum.” Artforum, September 2025. Accessed 8 Oct. 2025. https://www.artforum.com/features/yuk-hui-daniel-birnbaum-interview-1234733869/

Cope, B., & Kalantzis, M. (2024). On Cyber-Social Learning: A Critique of Artificial Intelligence in Education. In *Trust and inclusion in AI-mediated education: Where human learning meets learning machines* (pp. 3-34). Cham: Springer Nature Switzerland. https://link.springer.com/chapter/10.1007/978-3-031-64487-0_1

Fukuyama, F. (1989). The End of History?. The national interest, (16), 3-18. https://www-jstor-org.proxy2.library.illinois.edu/stable/24027184?seq=2


### Questions

Again, feel free to respond to any or all of the following:

1. Braidoti, Katherine Hayles, Hui, and Kalantzis and Cope all voice cautious optimism for a cyborgian or cybernetic future in which human and machine retain their distinctions even while they are synthesized. Do you find their respective programs compelling? 
2. Early in the course, one student noted reservations about historicism (the view, broadly, that history has a given trajectory or goal). But the *absence* of an historical plan or strategy might also be viewed as a problem. What are your thoughts? 
3. Our final task will be to develop a curriculum that addresses, in some general sense, the literacy of both machines and people. Thinking back across the concepts introduced by this course, do you feel you have the resources for this task? If not, what is missing?
