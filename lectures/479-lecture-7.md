

## Bitter Lessons, Stochastic Parrots, Errant Agents: From Criticism to Immanent Critique?


- Overview of examples of *external* (Goodlad and Stone; Gebru and Torres) and *internal* (Sutton, LeCun) critique
- Boosters / doomers? Hype vs critique?  How do we address profound, even irreconciliable difference?
- Example: TESCREALism illustrates how criticism can be co-opted and made ironic
- "What is immanent Critique?" (Stahl) 


> Marc Andreessen, the last of whom included “TESCREAList” in his Twitter profile for several weeks in 2023 (Gebru & Torres 2024)

```notes
We have traversed a lot of conceptual territory in this course, and this week we move to another term: critique, and a related term of criticism. 

All of the articles and videos offer insight on different AI and machine learning topics. I'll be providing very brief coverage of two lines of criticism: what we can think of external (Goodlad and Stone; Gebru and Torres) and internal (Sutton, LeCun) criticism.

But the area I really want to focus on is the question raised by the Stahl article: what is immanent critique?

I raise this question not only because it arises in the context of Hegelian scholarship - and because he is the key thinker to inaugurate a concern about this question. It is because one of the difficulties today concerns how we address deep epistemic divides between proponents and critics of AI. Let me take as an example the remark Gebru and Torres make in the context of their article on TESCREALism:

> Marc Andreessen, the last of whom included “TESCREAList” in his Twitter profile for several weeks in 2023

Now this term is of course a critical one, and we can assume Andreessen is both aware of this and proudly applies the term to himself *ironically*. So here we get a key difficulty in the context of critique and criticism: today it is very easy simply to embrace the criticism and move on. If criticism is simply a game of name-calling and point-scoring, we might say it is ultimately ineffectual - something like a fashional pose we adopt, a sign of learning and distinction. How do we make criticism *stick*? This is the problem Stahl - and Hegel before him – seek to address via the idea of an immanent critique. 
```

---


### Towards Critical AI: Beyond Chatbot-K


 - Mistaking statistical processes for signs of intelligence
 - Extreme hype - both of the benefits and dangers of AI (booster-doomerism)
 - Corporate offloading of risks and costs to the public
 - Poor science: "misleading terminology, flawed technical benchmarks, and proprietary datsets" 
 - "ELIZA" effects of anthropomorphism
 - Misplaced attribution of experience to machine learning
 - "Amplification of biases and stereotypes"
 - "Misinformation and Degradation of the Internet"
 - "Copyright Infringement, Lack of Consent"
 - Environmental effects
 - Corporatization / privatization of research
 - "Exploitation of Human Labour"
 - "Frictionless Knowing"
 
```notes
In the first two readings, we see criticism applied to AI from the standpoint of scholars working in the field of what has been termed "critical AI studies". These are what Stahl might term "external" criticism: levelled at the general field of AI from outsiders (scholars typically working in the humanities and social science traditions). 

The article by Goodlad and Stone is an introduction to a recent special issue launched by a new journal, in fact entitled "Critical AI". It develops a wide-ranging and lengthy but useful array of critical AI topics. These summarize a number of topics many of you will be familiar with, and that we have dealt with in previous weeks. 


```
 
---

### TESCREALism: "Transhumanism, Extropianism, singularitarianism, (modern) cosmism, Rationalism, Effective Altruism, and longtermism"

- Blends narratives of scientific progress with transhumanist fantasies of mortality transcendence
- Connected with history (and recent resurgence) of racialized eugenics
- AGI (Artificial General Intelligence): Utopia and Apocalypse: Two Sides of the Same Coin? 
- What is downplayed in the "existential" crisis of AGI is the perpetuation of everyday risks: algorithmic racism and sexism, environmental harms and the concentration of political power

```notes
The article by Gebru and Torres develops criticism in another direction: what I would call an effort to characterize the "spirit" of Silicon Valley, which today motivates the development of Artificial Intelligence. Their description of TESCREAL seeks to join together otherwise disparate and even contradictory elements. On the one hand, the pursuit of scientific, mathematical and technological progress. On the other, the fantasy – at least for today – of an overcoming of mortality and the limits of life, which fall under the banner of transhumanism. 

They further develop their analysis with a comparison with eugenics: a movement that coincides with the history of statistics, which underpins machine learning. This they connect specifically with the recent focus on AGI. They note one of the recurring oddities of the generative AI moment: that those researching or investing to develop AI are often those also expressing concerns about its existential risk. What is downplayed in the "existential" crisis of AGI is the perpetuation of everyday risks: algorithmic racism and sexism, environmental harms and the concentration of political power.

```

---

### The "Godfather" Critiques: The Problem of Experience

- Both LeCun and Sutton discuss the limits of Transformer-based systems
- LLMs cannot "experience"; they are useful regurgitators of human experience  
- Echoes of Goodlad, Stone, Gebru and Torres: LLMs overrated
- **But**: each suggests alternatives that can address limits of LLMs: 
  - Sutton sees Reinforcement Learning as the key to genuine (as opposed to imitative) AI.
  - LeCun argues (in one of the supplementary readings) for AI that is modelled more closely on childhood development.


```notes
In the follow-up two videos, featuring Yann LeCun and Richard Sutton, we see a different type of criticism. Both are highly respected scholars in the field of Artificial Intelligence, responsible for some of the foundational developments in neural networks and reinforcement learning. Both are however critical about the overreliance upon the Transformer architecture we discussed in Week 4. In different ways, each thinks language models can never arrive at general - much less super - intelligence, because they are inherently limited. 

Both offer criticisms that overlap, but also have differences, certainly in how each sees these limitations being overcome. For LeCun, this limitation relates to the relatively *static* nature of the language model. For both, the limits of language models relate instead to the lack of *experience*.
```



---

### Criticism Types in Machine Learning

- *External* critics are well-informed scholars outside ML, offering outsider perspectives.
- *Internal* critics are ML experts questioning the field's own evolution.
- Both viewpoints highlight different concerns about progress and direction.
- But are they *convincing*? *Persuasive*?

```notes
So far we have examined two examples of two types of criticism. The first we can describe as *external*: developed by well-informed scholars who sit, like most of us, outside the immediate field of machine learning. The second we can describe as *internal*: developed by experts in machine learning itself, who are nonetheless critical of the way the field has evolved. 

But whether we agree with these different critiques or not, we might still be troubled by whether *opposing* standpoints would find them convincing....
```

---

### "What is Immanent Critique?"

- Immanent critique: unfolds the system’s own logic.
- Distinguishes object (target of criticism) from standpoint (critic’s explicit position).
- Example: Goodlad & Stone critique
  - Object: AI or LLMs 
  - Standpoint: equality, sustainability, verifiability - *liberal* values? 


```notes
Now we turn to the fifth article by Stahl, "what is immanent critique?" What *is* immanent critique? And what is its relevance for us, to think about machine and human learning?

Firstly, the purpose of immanent critique is to pose greater difficulties for those who would like to rebut that critique - because it aims to show it stems from the same *ground*, or shared premisses, as that which motivates the rebuttal.

Let's move on by introducing a couple of further terms: the *object* and the *standpoint* of critique. The object is the thing that we wish to judge with our criticism, while the standpoint is the position we adopt, implicitly or explicitly, when we do so. For example, the Goodlad and Stone article is  directed toward the *object* of artificial intelligence, and their *standpoint* is that technologies such as AI should be equitable, sustainable and fair with respect to the work of creators and workers. 
```

---

### Transcendental vs Immanent Critique

- Transcendental critique: standpoint is *external* to the world of the object.
- A transcendental god creates but remains aloof; an immanent god is embedded in creation.
- Hegel’s philosophy exemplifies immanence, seeing Spirit evolve through history.
- **Immanence** implies that *human development* mirrors *divine development*

```notes
We'll next introduce another term: the opposite of immanent critique, as a way for us to get into what can be quite a difficult idea to grasp, through the form of contrast. It is a term known as *transcendental* critique. What is transcendental, and how does it differ from immanent? 

Both ideas come in fact from the world of religion. A transcendental god is one who sits outside the world. Who perhaps gives the world its start, via an act of divine creation, but thereafter remains aloof, watching from afar, perhaps only returning at some future date of Judgment. An immanent god, by contrast, is one who is embedded in our world, who is able to act upon it, or who is infused in every act of creation. We have already seen how Hegel's view is deeply immanent: the Spirit is always in a process of maturing, developing, evolving. This includes the Spirit in the godly sense - he means something like god is itself coming into being through the creation of the world, of us, of history, of technology. God's immanence means, for Hegel, that we are not only part of god's plan; our development is also the development of god, or of spirit. Hegel is in some sense of the term, a transhumanist. 
```


---

### Immanent Critique arises from Contradiction

- Missteps in history: reduced knowledge, stalled progress.
- Ideal outcomes (equality, harmony) clash with reality: wars, xenophobia rise.
- Contradiction between **ought** and **is** 
- This contradiction fuels critical examination of our cultural trajectory.

```notes
So what about critique? Let's stay with Hegel's idea of immanence a moment longer, even if we treat it just as a convenient fiction. If we assume our history - the history of our species, our culture, our technology – is the coming into being of god, then we might also assume there are missteps. These might be moments when god's development is arrested, held up, because we stray from the proper path. How do we know this? We might believe god's ultimate plan is for the realization of Absolute Knowledge; yet we might feel we are instead losing knowledge, becoming less intelligent, less educated - straying from the tendency towards god's own eventual realization. 

In more concrete terms: we might believe our culture, science and technology *should* be leading us towards greater equality, mutual recognition, self-consciousness and awareness, political harmony, sustainability and so on. But then we notice in practice the opposite is true: wars continue to be fought, xenophobia – a kind of lack of recogition - is on the rise. 

In short, we notice a contradiction between what *ought* to be the case, and what *is* actually the case. And this leads us to criticism.
```


---

### Immanent Critique in Hegelian Thought

- Standards of right and wrong arise from historical evolution, not divine decree.
- **Dogmatic** beliefs resist challenge because they rely on transcendental conditions.
- Rational knowledge must acknowledge historical contingency to allow revision.
- Immanent critique enables detection and correction of irrational foundations.

```notes
Now what makes this criticism *immanent*? In our story so far, we might note we do not in fact have ten commandments or a set of equivalent rules laid out for us. Instead, it is through our own evolution that we develop a sense of right and wrong, or the standards that allow us to talk about what *ought* to be the case. This sense that our standards of judgment arise historically – via our own trial and error - is fundamental to Hegel's picture, and part of his legacy is precisely this idea of critique that is immanent to our own historical process – and to not some *deus ex machina* who presides over us. 

Why does this matter? One of the problems Hegel is trying to address - just like Kant before him – is that of *dogmatism*. Dogmatic beliefs are those that cannot be challenged, because in some way they refer to a transcendental conditions: for example, to a god that *I* believe in, but that *you* do not. Hegel wants to say that dogmatic knowledge, even when it looks like it is true, still rests upon what might be subjective and even irrational beliefs. Such knowledge is itself therefore ultimately irrational. 

Rational knowledge, on the contrary, needs to be based upon foundations that understand themselves to be historically contingent - even if we don't know of any better. Then if we see contradictions, these foundations are capable of being revised - this is the sign of a properly rational knowledge, and the basis for immanent critique. 
```

---

### The Problem of Transcendental Critique 

- Transcendental Critique relies on shared *a priori* values (e.g. liberalism)
- *Divergent* value systems cause perceived dogmatism or skepticism.
- Historical process can unite parties by showing values as *earned* (not divinely bestowed on this or that group).


```notes

Why is this important? In the final analysis, transcendental critique - the kind of criticism that depends upon standards brought from outside the object – only holds if the speaker and the listener share some *a priori* values. For example liberalism: if we are both liberals, your critique of how AI (for example) offends liberal sensibility is likely to resonate. But what if I am opposed to liberalism? We are stuck: you appear to me as dogmatic; I appear to you as sceptical. What breaks this impasse? If you can show me how we are together by a historical process to understand certain values, such as equality, as precious - not as god-given, but rather acquired via painful historical trial-and-error. This doesn't require us both to be atheist; only that we see how history delivers us a set of ideals that seem to improve upon earlier versions. Then you might lead me to a conviction that AI (or something else) contradicts this historical and ethical achievement. Pointing out such a contradiction leads to a criticism that is *immanent*, because it does not depend us having some shared metaphysical values - only that we both acknowledge this historical process (a separate problem).
```

---

### Immanent Critique and Dialectic Learning

- We evaluate objects against ethical standards - while also *reassessing* those standards.
- This reciprocal judgment embodies Hegelian experience, driving self-consciousness toward forward.
- The process refines both object and norm, leading toward *Absolute Knowledge*.
- It exemplifies genuine learning through continuous recalibration of ideas and values.

```notes
As the Stahl paper argues, this process of immanent critique involves a complex dialectic exchange: we judge an object against a normative, ethical standard, like the printing press, and then we also judge our own standards too - recalibrating both object and stanard together. This process, as Stahl reminds us, is what Hegel means by the term "experience", and is the genuine form of learning that takes us forward toward self-consciousness and, ultimately, Absolute Knowledge. 
```

---

### AI, Expectations, and Self‑Critique

- Shoud our hopes for technology should *evolve alongside* AI assessment?
- Consider AI as a catalyst for *reflexive pedagogy* (following Hegel) - or potential *social domination* (following Marx)
- How is AI reshaping standards and foundations of critical self‑examination?

```notes
How do we bring this all home in the context of AI? First, we might want to think in terms of our own processes of response to AI as an object: how do we judge it against what we take to be our normative expectations of technology? Or in less formal language: what are our hopes for technology, and in what ways does AI fail to live up to them? 

But second, how are our hopes themselves being modified as we start to assess AI? Can we begin to see that our standards themselves need to evolve - not just that we need new rubrics, for example, but that the foundations for those rubrics also need examination?

And on a wider front, leading us towards the differing visions of history and futurity we will discuss next week: is the advent of AI itself the kind of technology that might be essential to the very task of our critical self-examination? Is it the technology that can help transform the admitted obscurity of reflexive immanent critique? Can it lead us toward, as Mary and Bill might say, reflexive pedagogy? Or, as Gebru and Torres claim, is the AI project instead a massive fantasy projected by a disguised eugenics movement - a contemporary form, as Stahl discussed in relation to Marx, of "social domination" (rather than "conceptual self-determination")?
```


---


### Immanent Critique: Example of the Printing Press


- Printing press: dual role in *democratizing knowledge* and *spreading misinformation*.
- Democratic values stem partly from *technology-enabled education*.
- Calls for reflexive critique, balancing *object’s shortcomings* with *realistic standards*.
- Emphasizes need to anticipate future tech impacts by learning from past innovations.

```notes
Let's examine now the case of the printing press, as an example of an immanent critique of technology. We can look back upon the arrival of this invention and note its pros and cons: its democratization of information, on the one hand, and its propensity for the spread of misinformation, on the other. But then we might step back to say: where does our *desire* for democracy come from? In other words, what explains the basis of our judgment? We might say: we learn it, from parents, schools, community, all of which instils in us an appreciation for democracy, for an equal right to vote, and so on. But we might probe further, and note our education is in part depedent upon the low cost of the technologies for storing and disseminating information itself. These include the printing press, or derivatives from it. So a proper "immanent" critique acknowledges our debt to the very technology that we are busy critiquing. 

Immanent critique involves then a process of trying to bring together the objects and our standards for assessing them in a single account. If we didn't have the object of the printing press, we might not have the benefit of several hundred years of the democratization of education to allow us to judge it. And this must form *part of our judgment*! 

However that does not mean that critique needs to become mute. Instead it can observe the emergence of contradictions: when, for example, the technology of print is used to subvert the ideals of democracy and equality that it also gave rise to. In that case, we need to deliberate: either the object is not living up to the standards we expect of it; or our standards may have been too high; or some combination of the two. We need to be *reflexive* in our critique, and consider how both the object and the critique itself might need to be recalibrated. 

Now this becomes more difficult in terms of technologies of the present, because we do not yet experience its benefits nor its deficits fully. So we have to *anticipate* many of its effects, while also acknowledging the role of similar technological innovations, like the printing press and the Internet, in the past. 
```


---

### Toward a Reflexive Pedagogy of AI? AI and Immanent Critique


a. the pros and cons of the technology itself - will it improve education? What are criteria for evaluating improvement?
b. whether our existing standards are sufficient for evaluation - or do we need new ways to evaluate? How do we evaluate our evaluations?
c. Can AI be a reflexive technology - one that helps us develop a critique that raises the standards of both human and machine? What would be criteria for assessing this?

```notes
In breakout groups, we want to try to develop a rubric for a reflexive, immanent critique!

We'll start by imagining we are evaluating a new AI technology for education. We want to develop a rubric that seeks to judge the following:

a. the pros and cons of the technology itself - will it improve education? What are criteria for evaluting improvement?
b. whether our existing standards are sufficient for evaluation - or do we need new ways to evaluate? How do we evaluate our evaluations?
c. Can AI be a reflexive technology - one that helps us develop a critique that raises the standards of both human and machine? What would be criteria for assessing this?
```


<!--
---

Sketching immanent critique

1. We could argue that both the history of technologies - such as the printing press and the Internet – and social progress has brought us standards that we apply to future technologies. These must also help to promote democracy, equality and liberty. 

2. We could also argue that technologies and the "will to power" have led to a society that is increasingly centred on control, domination and value extraction. Certain technologies might then surprise in how they seem to run against this trend, opening up potential for liberation. 

Both constitute examples of immanent critique, because we are judging the present against the expectations set by the past - history - not some values imported via religion or other means.

-->

---





<!--
We might begin by asking the obvious question: how is critique different from criticism? Often the terms are used interchangably. 

But as I suggested in the write-up for this week, Hegel's predecessor Immanuel Kant really defined the term for us. For Kant, critique is the development of an argument about what can and cannot be said about a topic. The Critique of Pure Reason determines what can be known by science, and what cannot. The Critique of Practical Reason, on the other hand, describes how we can know what is moral and what is not - how we ought to regulate our conduct in practical day-to-day life. Finally, the Critique of Judgment describes the conditions under which we apply judgments about beauty. In short, the three Critiques describe how we determine what is true, what is good, and what is beautiful. 

Critique in this sense acts like meta-criticism; it establishes the ground by which criticism - 'that is false / evil / ugly' -  can be applied. How does this relate to our contemporary situation with respect to machine learning? First, I would say much of the discourse around AI today remains locked into *criticism*: relatively little has sought to explicate what constitute the limits of what a machine can learn, or, just as importantly, what machine learning means for the limits of human learning. 

Kant presumes a relatively static world, made up of space, time, and many other things, including things like us, capable of asking questions about that same world. With Hegel, we get a similar picture, but injected now with a dynamic sense of how we as humans can conceive of that world. For Hegel, there are no fixed categories. Instead we work our way through the categories we inherit, discarding some, modifying others, as we test the sum of our knowledge against how we take the world to be. In this very specific sense, Hegel is the first proper philosopher of **technology**: because he allows for the possibility that, alongside and as part of our collective scientific adventure, instruments and machines could revise our understanding of the world quite fundamentally.

Hence Hegel would not have necessarily shocked by profound scientific discoveries and technological developments after his time: Darwin, Freud, Einstein, computers, or machine learning. Instead he would see these as proving his point against Kant - critique must always absorb into itself new 'moments' of discovery. 

Today though, I'm not sure we have quite the same generosity and openness to the prospects of a technology that, as we saw last week, is asking us to align ourselves with the new possibilities it establishes.
-->





<!-- Changing relationship between human and machine. "Assistant" is the wrong metaphor: assumes anthropomorphic "other". Why not a new appendage? Why not acknowledge AI is a powerful cyborgian supplement - like writing, and other technologies?
 -->


<!--


First, a little background: Hegel, a guiding light for this course, was following closely in the footsteps of another German philosopher, Immanuel Kant. Kant introduced the concept of critique in three major works:

 - Critique of Pure Reason (what we today would call, roughly, "Science")
 - Critique of Pratical Reason (what we would call "morality" and "ethics")
 - Critique of Judgment (what we would call "aesthetics", and also art, literature, film studies etc)

"Critique" was not simply meant as a form of criticism, but rather a radical re-thinking of the possibilities of knowledge. For Kant, critique avoids the twin problems of sedimented knowledge: dogmatism (insisting you know what is right) and scepticism (being doubtful that anything is right).

Hegel picks up on Kant's concept of critique, offering (as we might suspect) a *critique* of critique. Where Kant sought to identify limits of knowledge, Hegel saw these limits as themselves unnecessarily arbitrary. Hence the *Phenomenology*'s long road toward Absolute Knowledge.

In relation to AI, we are faced in many respects with similar terms of reference today. On the one hand: those who see AI as the path to unlimited knowledge (the dogmatists). On the other: those who deny that path entirely (the sceptics). And then those who, like Kant and Hegel, seek to describe the very map and contours of what is knowable by machines at all. Are they simply powerful statistical engines? Or potential oracles that, given time, might overcome limits of their training data?

Quite aside from these abstract concerns, there is a fast-growing literature on the negative social effects of AI. We saw some of this already last week in the discussion of alignment. But not all criticism sees alignment as a fix; indeed, for many, the issues are more profound and structural, relating to who *owns* the models, the compute power, the data centres, and the potential means for social surveillance and cognitive lock-in. Even if we remain unconcerned about *doomer* scenarios, many are worried about the intense concentration of resources – including energy, water and real estate, as well as data, computation and human resources – involved in AI today. 

This week we review a small sample of this literature, to gain a sense of how machine learning is far from a political neutral technological development. Yet might there be a sense that the machines are learning from this criticism too?

This week I've added a number of papers that touch upon both critique and criticism of AI. As with previous weeks, pick readings that might interest you and absorb what you can. 

-->

