# Hegel Pedagogy AI - Environment Configuration
# Copy this file to .env and fill in your API keys

# ====================
# AI Provider API Keys
# ====================

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4  # Options: gpt-4, gpt-4-turbo, gpt-4o, gpt-4o-mini, gpt-3.5-turbo

# Anthropic Configuration  
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022  # Options: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307

# Groq Configuration
# Get your API key from: https://console.groq.com/
GROQ_API_KEY=gsk_your-groq-api-key-here  
GROQ_MODEL=llama-3.1-70b-versatile  # Options: llama-3.1-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768

# OpenRouter Configuration
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-your-openrouter-key-here
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet  # Options: anthropic/claude-3.5-sonnet, openai/gpt-4, meta-llama/llama-3.1-70b-instruct

# Google Gemini Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_MODEL=gemini-2.5-flash  # Options: gemini-2.5-flash-image-preview, gemini-2.5-flash, gemini-2.5-pro, gemini-1.5-flash, gemini-1.5-pro

# ====================
# AI Service Configuration
# ====================

# Default AI Provider (if multiple are configured)
# Options: openai, anthropic, gemini, groq, openrouter
DEFAULT_AI_PROVIDER=openai

# AI Response Settings
AI_TEMPERATURE=0.7  # Creativity level (0.0 - 2.0)
AI_MAX_TOKENS=2000  # Maximum response length

# ====================
# Application Settings  
# ====================

# Development mode
NODE_ENV=development

# Logging level
LOG_LEVEL=info

# ====================
# Usage Notes
# ====================

# You only need to configure the providers you plan to use.
# The application will automatically detect which providers are available
# based on which API keys are provided.

# Priority order (if multiple providers are configured):
# 1. The provider specified in DEFAULT_AI_PROVIDER
# 2. First available provider in this order: openai, anthropic, gemini, groq, openrouter

# Model Selection:
# - Each provider has a default model that will be used if not specified
# - You can override the model on a per-request basis through the UI
# - Check each provider's documentation for the latest available models

# Cost Considerations:
# - OpenAI GPT-4: Higher cost, excellent quality
# - Anthropic Claude: Competitive pricing, great for reasoning
# - Google Gemini: Competitive pricing, multimodal capabilities
# - Groq: Very fast inference, cost-effective
# - OpenRouter: Access to multiple models, pay-per-use

# Rate Limits:
# - Each provider has different rate limits
# - The application includes automatic retry logic with exponential backoff
# - Consider upgrading to paid tiers for higher limits if needed